#!/usr/bin/env python
import httplib2, re
import numpy as np
from socket import getfqdn
from pprint import pformat, pprint
from time import time
from json import loads
from execo import logger, Process, SshProcess, sleep, Host
from execo.log import style
from execo_g5k import OarSubmission, oarsub, get_current_oar_jobs, get_oar_job_info, \
    wait_oar_job_start, get_host_attributes, get_oar_job_nodes,\
    default_frontend_connection_params, get_host_site
from argparse import ArgumentParser, RawTextHelpFormatter
from execo_engine import copy_outputs
from execo_g5k.config import default_frontend_connection_params
from execo_g5k.topology import g5k_graph
import networkx as nx

h1 = httplib2.Http()
site = getfqdn().split('.')[1]

def main():
    """ """
    args = set_options()
    hosts = get_hosts(args.job_name, args.site)
    check_energy(args.machine, hosts, args.stress_time)
    check_network(args.machine, hosts, args.stress_time)

def set_options():
    prog = 'kwapi-g5k-check'
    description = 'This tool check the consistency of Kwapi energy monitoring system.' + \
        ' It performs a reservation if no running job is found '
    parser = ArgumentParser(prog=prog,
                            description=description,
                            formatter_class=RawTextHelpFormatter,
                            add_help=False)
    optinout = parser.add_argument_group(style.host("General options"),
                    "Define mode and controls I/O.")
    optinout.add_argument("-h", "--help",
                          action="help",
                          help="show this help message and exit")
    optinout.add_argument("-j", "--job-name",
                          default="Kwapi-check",
                          help="Name of the job to be used for the check.")
    optinout.add_argument("-m", "--machine",
    		              default='kwapi',
                          help="name of the kwapi instance")
    optinout.add_argument("-s", "--site",
                          default=site,
                          help="Site to be checked")
    optinout.add_argument("-c", "--cluster",
                          default=None,
                          help="Cluster to check (WARNING: not recommanded)")
    optinout.add_argument("-t", "--stress-time",
                          default=30,
                          help="Duration of the stress")
    optinout.add_argument("-T", "--testing",
                          default=False,
                          help="Use testing queue")
    
    optio = optinout.add_mutually_exclusive_group()
    optio.add_argument("-q", "--quiet",
                       dest="quiet",
                       action="store_true",
                       default=False,
                       help="Run without printing anything")
    optio.add_argument("-v", "--verbose",
                       dest="verbose",
                       action="store_true",
                       default=False,
                       help="Run in verbose mode")
    
    
    args = parser.parse_args()
    
    if args.verbose:
        logger.setLevel('DEBUG')
    elif args.quiet:
        logger.setLevel('WARN')
    else:
        logger.setLevel('INFO')
    
    copy_outputs('kwapi_check.log', 'kwapi_check.log')
    
    return args

def get_hosts(job_name, site):
    """ """
    # Retrieving job or submitting a new one
    logger.info('Checking for a running job')
    current_jobs = get_current_oar_jobs([site])
    job_id = None
    for job in current_jobs:
        info = get_oar_job_info(job[0], job[1])
        if info['name'] == job_name:
            job_id = job[0]
            break
        
    if job_id:
        logger.info('Running job found, %s', job_id)
        job = (job_id, site)
    else:
        logger.info('No running job, submitting a new one')
        options = ""
        if cluster:
            options += " -p \"cluster='%s'\"" % cluster
        if testing:
            options += " -q testing"
        job = oarsub([(OarSubmission(resources = "nodes=BEST", name=job_name, 
                      job_type='allow_classic_ssh', additional_options=options), site)])[0]
    
    logger.info('Waiting for job start')
    wait_oar_job_start(job[0], job[1])
    logger.info('Retrieving node list')
    hosts = get_oar_job_nodes(job[0], job[1])
    
    return hosts


def check_energy(machine, hosts, duration):

    ## Checking that all nodes have a probe declared in Kwapi configuration
    
    resp, content = h1.request("http://" + machine + "." + site + ".grid5000.fr:5000/probes/", 
                               "GET")
    content = loads(content)
    
    # for host in hosts:
    #     if site + '.' + host.address.split('.')[0] not in content['probes']['power']:
    #         logger.warning('%s is not declared in Kwapi', host)
    #         hosts.remove(host)
    
    # Stressing hosts and retrieving power measures from Kwapi-API
    measures = {}
    i = 1
    for host in sorted(hosts, key=lambda x: int(x.address.split('.')[0].split('-')[1])):
        host_string = style.host(host.address.split('.')[0]) 
        if site + '.' + host.address.split('.')[0] not in content['probes']['power']:
            logger.warning('%s is not energitically monitored', host)
            continue
        n_proc = get_host_attributes(host)['architecture']['nb_cores']
        logger.info(str(i) + ' Host %s has %s cores', host_string, n_proc)
        ts = time()
        measures[ts] = {'stress': host.address}
        logger.info('Launching stress on %s', host_string)
        stress = SshProcess('killall stress; stress --cpu ' + 
                            str(n_proc) + ' --timeout '+ str(int(int(duration)/2)), 
                            host)
        wait = int(int(duration)/2)
        while True:
            resp, content = h1.request("http://" + machine + "." + site + ".grid5000.fr:5000/probes/", "GET")
            content = loads(content)
            
            if resp['status'] == '200':
                for probe, values in content['probes']['power'].iteritems():
                    if probe not in measures[ts]:
                        measures[ts][probe] = []
                    measures[ts][probe].append(values['value'])
            if not stress.started:
                if wait == 0:
                    stress.start()
                else:
                    wait = wait - 1
            if stress.ended:
                i += 1
                break
            sleep(1)
        logger.info('Stress ended, analyzing results')
        wait = int(int(duration)/2) 
        if site + '.' + host.address.split('.')[0] in measures[ts]:
            try:
                measure = measures[ts][site + '.' + host.address.split('.')[0]]
                first = np.mean(measure[:wait])
                last = np.mean(measure[wait+1:-1])
                med = np.median(measure[wait+1:-1])
                logger.info('%s: %s %s %s', host.address.split('.')[0], first, med, last)
                if abs(last - med) < abs(first - med):
                    logger.info(style.user1('OK')+ " " + host.address )
                else:
                    logger.info('Looking for a variation in other probes')
                    for probe in sorted(map(lambda host: unicode(site + '.' + host.address.split('.')[0]), hosts)):
                        measure = measures[ts][probe]
                        first = np.mean(measure[:wait])
                        last = np.mean(measure[wait+1:-1])
                        med = np.median(measure[wait+1:-1])
                        logger.debug('%s: %s %s %s', probe, first, med, last)
                        if abs(last - med) < abs(first - med) and last > first:
                            logger.error('Power from ' + host.address + 
                                    ' is recorded by probe ' + probe) 
                            logger.info(probe + ': ' + pformat(measure))
                            break
                    logger.error('No variation found on any probes, wrong record in API ?')
            except Exception, e: 
                logger.error('problem with probe ' + host.address.split('.')[0])
                print str(e)
        else:
            logger.error('probe %s is not monitored', host.address.split('.')[0])
            
        logger.info('Waiting for energy decrease')
        sleep(30)

def check_network(machine, hosts, duration):
    gr = g5k_graph()
    for host in hosts:
        gr.add_host(host.address)
    
    server = Process('iperf -s').start()
    
    i=1
    try:
        for host in sorted(hosts, key=lambda x: int(x.address.split('.')[0].split('-')[1])):
            logger.info('Checking host %s', style.host(host.address))
            net_in = {}
            net_out = {}
            switch = list(nx.all_neighbors(gr, host.address))[0]
            probe_in = site + '.' + switch.split('.')[0] + '_' + host.address.split('.')[0]
            probe_out = site + '.' + host.address.split('.')[0] + '_' + switch.split('.')[0] 
            
            iperf = SshProcess('iperf -c ' + site + ' -r -t ' + str(duration), host,
                               connection_params={'user': default_frontend_connection_params['user']}) 
            while True:
                resp, content = h1.request("http://" + machine + "." + site + ".grid5000.fr:5000/probes/", "GET")
                content = loads(content)
                if resp['status'] == '200':
                    try:
                        data_in = content['probes']['network_in'][probe_in]
                        data_out = content['probes']['network_out'][probe_out]
                    except:
                        print probe_in, probe_out
                        print sorted(content['probes']['network_in'])
                        print sorted(content['probes']['network_out'])
                        exit()
                        
                    net_in[data_in['timestamp']] = data_in['value']
                    net_out[data_out['timestamp']] = data_out['value']
                if not iperf.started:
                    iperf.start()        
                if iperf.ended:
                    i += 1
                    break
                sleep(1)
            
            print len(net_in), net_in.values()[0], net_in.values()[-1]
            print len(net_out), net_out.values()[0], net_out.values()[-1]
            
    finally:
        server.kill()
    
if __name__ == "__main__":
    main()
